{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffa3803-a90c-44aa-ae43-c5f7732418e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "from pathlib import Path, WindowsPath\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import pyboat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12521d0f-395b-45ee-aa1e-bb15917ca7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User arguments\n",
    "\n",
    "pattern = r'mask_tf(\\d+)_apoc_cell(\\d+)\\.json'\n",
    "port = 5005\n",
    "input_path = \"H:/PROJECTS-03/Pablo/oscillating/ppf005_third_analysis/metadata/raw\"\n",
    "nan_threshold = 0.8\n",
    "current_socket = 'localhost:8888'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cadf82-dfad-4cca-9b4e-240a9eaa2498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordering functions\n",
    "\n",
    "def ordering_function_tf(path):\n",
    "    \"\"\"Give the timeframe contained in the name of the json file as an integer.\n",
    "    Use to sort metadata files\"\"\"\n",
    "    \n",
    "    pattern = r'mask_tf(\\d+)_apoc_cell(\\d+)\\.json'\n",
    "    match = re.match(pattern, path.name)\n",
    "    return int(match.group(1))\n",
    "\n",
    "def ordering_function_cell(path):\n",
    "    \"\"\"Give the cell number contained in the name of the json file as an integer.\n",
    "    Use to sort metadata files\"\"\"\n",
    "\n",
    "    pattern = r'mask_tf(\\d+)_apoc_cell(\\d+)\\.json'\n",
    "    match = re.match(pattern, path.name)\n",
    "    return int(match.group(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f834cff9-edf3-40ce-a7a7-554690c85e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_subdirectory(subdirectory_path, pattern=pattern, df=df):\n",
    "    json_files = list(subdirectory_path.glob('mask_tf*_apoc_cell*.json'))\n",
    "    json_files.sort(key=lambda x: (ordering_function_cell(x), ordering_function_tf(x)))\n",
    "    cells = {re.match(pattern, file.name).group(2) for file in json_files} # Cell numbers as in the metadata file names\n",
    "\n",
    "    # Check whether cells is emptyy or metadata has been found, if so populate df with average intenstiy\n",
    "    if cells:\n",
    "        for cell in cells:\n",
    "            print(f'Recording cells {subdirectory.name}+{cell}')\n",
    "            json_cell = [json_file for json_file in json_files if 'apoc_cell'+cell in json_file.stem]\n",
    "            tfs = [int((re.match(pattern,json_file.name)).group(1)) for json_file in json_cell]\n",
    "            tfs.sort()\n",
    "            for (tf, json_file) in zip(tfs, json_cell):\n",
    "                with json_file.open('r') as file:\n",
    "                    data_dict = json.load(file)\n",
    "                    npixels = data_dict.get('npixels')\n",
    "                    intensity = data_dict.get('intensity')[1] if 'intensity' in data_dict and len(data_dict['intensity']) > 1 else None\n",
    "                    column_name = subdirectory_path.name+'_'+cell\n",
    "                    df.at[tf, column_name] = intensity/npixels\n",
    "    else:\n",
    "        print(f'No cell metadata in {subdirectory_path.name}')\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    # except AttributeError as e:\n",
    "    #     print(f'No cell metadata in {subdirectory_path.name}: {e}')\n",
    "    #     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb832a76-6269-4fd5-9a9f-c1658eb7a034",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = Path(input_path)\n",
    "subdirectories = list(root_folder.glob('*/'))[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b22828-27fc-4200-9d5d-e16dbb6adeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for subdirectory in subdirectories:\n",
    "    process_subdirectory(subdirectory, df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f6e291-cbef-4134-b4f5-c4763381ddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter traces with nan_values defined by nan_threshold\n",
    "\n",
    "df_cleaned = df.drop(columns=df.columns[df.isna().sum() > nan_threshold*len(df)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3304ccf-e928-416e-a455-8a733153198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0941b412-d3a4-4229-beec-3af4052e80a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook, show, push_notebook\n",
    "from bokeh.layouts import column, row\n",
    "from bokeh.models import Button, ColumnDataSource, CustomJS\n",
    "from bokeh.plotting import figure, curdoc\n",
    "from bokeh.application.handlers import FunctionHandler\n",
    "from bokeh.application import Application\n",
    "from bokeh.server.server import Server\n",
    "from tornado.ioloop import IOLoop\n",
    "import asyncio\n",
    "\n",
    "\n",
    "global valid_signals\n",
    "\n",
    "def modify_doc(doc):\n",
    "    # Initialize selected_plots as a ColumnDataSource\n",
    "    selected_plots_source = ColumnDataSource(data=dict(selected_plots=[]))\n",
    "\n",
    "    # Function to get selected plots in Python\n",
    "    def get_selected_plots():\n",
    "        return selected_plots_source.data['selected_plots']\n",
    "\n",
    "    # Function to create plots and buttons layout\n",
    "    def create_plots_layout():\n",
    "        plots = []\n",
    "        buttons = []\n",
    "\n",
    "        for col in df_cleaned.columns:\n",
    "            if col not in get_selected_plots():\n",
    "                source = ColumnDataSource(data={col: df_cleaned[col], 'x': range(len(df_cleaned))})\n",
    "                p = figure(width=250, height=250, title=col)\n",
    "                r = p.line('x', col, source=source, line_width=2, color='navy', alpha=0.8)\n",
    "\n",
    "                button = Button(label=col, width=60, button_type=\"success\")\n",
    "\n",
    "                def create_button_callback(plot, column_name, btn):\n",
    "                    def callback():\n",
    "                        selected_plots = selected_plots_source.data['selected_plots']\n",
    "                        if column_name in selected_plots:\n",
    "                            plot.background_fill_color = 'white'\n",
    "                            selected_plots.remove(column_name)\n",
    "                            btn.button_type = 'success'\n",
    "                        else:\n",
    "                            plot.background_fill_color = 'rgba(255, 0, 0, 0.1)'\n",
    "                            selected_plots.append(column_name)\n",
    "                            btn.button_type = 'danger'\n",
    "                        selected_plots_source.data = {'selected_plots': selected_plots}  # Update the data source\n",
    "                        global valid_signals\n",
    "                        valid_signals = df_cleaned.drop(columns=selected_plots_source.data['selected_plots']).columns\n",
    "                        # push_notebook()  # Ensure updates are reflected in the notebook\n",
    "                    return callback\n",
    "\n",
    "                button.on_click(create_button_callback(p, col, button))\n",
    "\n",
    "                plots.append(p)\n",
    "                buttons.append(button)\n",
    "\n",
    "        # Organize layout\n",
    "        plot_rows = []\n",
    "        for i in range(0, len(plots), 5):\n",
    "            plot_row = plots[i:i+5]\n",
    "            button_row = buttons[i:i+5]\n",
    "            plot_rows.append(row(*plot_row, column(*button_row)))\n",
    "\n",
    "        layout = column(*plot_rows)\n",
    "        return layout\n",
    "\n",
    "    # Create the initial layout\n",
    "    layout = create_plots_layout()\n",
    "\n",
    "    # Button to print excluded plots\n",
    "    print_button = Button(label=\"Print list of excluded plots\", width=200, button_type=\"primary\")\n",
    "    def print_selected_plots():\n",
    "        print(get_selected_plots())\n",
    "        # push_notebook()  # Ensure notebook updates\n",
    "    print_button.on_click(print_selected_plots)\n",
    "\n",
    "    # Button to rerender without selected plots\n",
    "    rerender_button = Button(label=\"Exclude selected plots\", width=200, button_type=\"warning\")\n",
    "    def rerender_plots():\n",
    "        new_layout = create_plots_layout()\n",
    "        doc.clear()  # Clear the current document\n",
    "        doc.add_root(column(new_layout, print_button, rerender_button))\n",
    "        # push_notebook()\n",
    "    rerender_button.on_click(rerender_plots)\n",
    "\n",
    "    # Add the layout and buttons to the current document\n",
    "    doc.add_root(column(layout, print_button, rerender_button))\n",
    "\n",
    "# Create the application\n",
    "app = Application(FunctionHandler(modify_doc))\n",
    "\n",
    "\n",
    "# Display app\n",
    "# show(app, notebook_handle=True) - Carefull to push notebook\n",
    "\n",
    "# Or do it through a server\n",
    "\n",
    "#  Start the Bokeh server\n",
    "# server = Server({'/': modify_doc}, port=4996)\n",
    "#  server.start()\n",
    "\n",
    "# def show_app():\n",
    "#     server.io_loop.add_callback(server.show, \"/\")\n",
    "#     server.io_loop.start()\n",
    "\n",
    "# show_app()\n",
    "\n",
    "#########################\n",
    "# Integrate with the current Jupyter server -- To be checked\n",
    "server = Server({'/': modify_doc}, port=port, io_loop=IOLoop.current(), allow_websocket_origin=[current_socket, \"localhost:\"+str(port)])\n",
    "\n",
    "async def show_app():\n",
    "    server.io_loop.add_callback(server.show, \"/\")\n",
    "    await server.io_loop.start()\n",
    "\n",
    "# Integrate with the Jupyter notebook event loop\n",
    "loop = asyncio.get_event_loop()\n",
    "if loop.is_running():\n",
    "    loop.create_task(show_app())\n",
    "else:\n",
    "    loop.run_until_complete(show_app())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd606828-de15-42d3-ad22-4aa360a3116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store valid signals\n",
    "\n",
    "df_cleaned[valid_signals].to_csv('./valid_signals_ppf005')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5058cef9-2300-49ad-8e52-b83eb59ea44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## HERE GOES AN ITERATIVE WAY TO DECIDE WHAT TO DO WITH NAN VALUES -- TO BE DONE ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90e7b98-440e-4b6c-a77e-f8ca085876c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOP SERVER AND FREE PORT\n",
    "\n",
    "server.io_loop.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(devbio-napari-cupy)",
   "language": "python",
   "name": "devbio-napari-cupy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
